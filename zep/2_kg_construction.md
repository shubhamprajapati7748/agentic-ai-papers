
# âœ… 1. Episode Subgraph (Gâ‚‘) â€“ â€œRaw Memory Layerâ€

Think of this layer as the **diary** of everything the system sees.

### What is stored here?

* Every incoming **message**, **event**, or **JSON object**
* Exactly *as it was received*
* With **timestamps**, **who said it**, and **metadata**

### Example

User and Agent have this conversation:

```
User (2025-01-05 10:30): I bought a MacBook Air yesterday.
Assistant: Oh nice! When did you decide to upgrade?
User: Last week. My old laptop was too slow.
```

The Episode Subgraph stores these as separate nodes:

| Episode Node ID | Content                             | Timestamp   |
| --------------- | ----------------------------------- | ----------- |
| E1              | â€œI bought a MacBook Air yesterday.â€ | Jan 5 10:30 |
| E2              | â€œWhen did you decide to upgrade?â€   | Jan 5 10:30 |
| E3              | â€œLast weekâ€¦â€                        | Jan 5 10:31 |

No processing. No summarization.
Just **raw memory**.

This ensures:
âœ” Nothing is lost
âœ” Future extraction can be more accurate
âœ” You can re-extract facts if LLMs improve

---

# âœ… 2. Semantic Entity Subgraph (Gâ‚›) â€“ â€œUnderstanding the World Layerâ€

This layer tries to **understand what each episode means**.

Zep uses LLMs and embeddings to pull out:

### A. **Entities**

These are â€œthings in the worldâ€:

* People
* Places
* Devices
* Organizations
* Concepts

### B. **Facts (Edges)**

Relationships between entities:

* â€œUser â†’ purchased â†’ MacBook Airâ€
* â€œMacBook Air â†’ purchase_date â†’ Jan 4â€
* â€œUser â†’ had_old_device â†’ Laptopâ€

---

## ğŸ” Example (continued)

From E1:

> "I bought a MacBook Air yesterday."

Zep extracts:

### Entities:

* **User**
* **MacBook Air**
* **Purchase Event**

### Fact:

```
(User) --purchased_on(2025-01-04)--> (MacBook Air)
```

From E3:

> â€œLast week. My old laptop was too slow.â€

Zep extracts:

### Entities:

* Old Laptop
* Purchase Decision Time

### Facts:

```
(User) --decided_upgrade_on(2024-12-29)--> (MacBook Air)
(User) --previous_device--> (Old Laptop)
```

---

## ğŸ§  Important: Entity Resolution

Different messages may refer to the same entity in different ways.

Example:

* â€œMacBook Airâ€
* â€œMy new MacBookâ€
* â€œThe Apple laptopâ€

Zep needs to detect theyâ€™re the **same object**.

How it works:

1. Embed names
2. Compare similarity
3. Sometimes ask LLM: â€œAre these the same entity in this context?â€

So all references collapse into a single entity node:

```
(MacBook Air)
```

This avoids duplication and creates long-term consistency.

---

## ğŸ§© Important: Fact Deduplication

If a user repeatedly says the same fact:

* â€œI live in Mumbai.â€
* â€œMy home is in Mumbai.â€

Zep avoids adding duplicate edges; instead, it updates confidence or timestamps.

---

## ğŸ•’ Temporal Extraction (critical feature)

Zep reads **when facts are valid**, not just what they are.

Example from the conversation:

* â€œI bought a MacBook Air yesterday.â€ â†’ valid on **Jan 4**
* â€œLast week I decided to upgrade.â€ â†’ valid on **Dec 29**

These become **temporal edges** stored with validity windows:

```
(User) --purchased(MacBook Air)--> valid: Jan 4 2025
(User) --decided_upgrade--> valid: Dec 29 2024
```

This is the â€œtemporal knowledge graphâ€ innovation.

---

# âœ… 3. Communities Subgraph (Gâ‚câ‚) â€“ â€œHigher-Level Understanding Layerâ€

Once the graph has a bunch of entities and facts, Zep tries to find **clusters** of related concepts.

This helps the memory system understand *themes* in a userâ€™s life or business environment.

### How communities are built:

* Use **label propagation algorithm**
* Cluster entities that:

  * Frequently co-occur
  * Are closely connected
  * Belong to same topic

### Example Community

From earlier conversation:

Entities involved:

* MacBook Air
* Old Laptop
* Upgrade Decision
* Purchase Event
* User
* Laptop Performance

They cluster into a **community** called:

```
â€œLaptop Upgrade Journeyâ€
```

The system also creates:

* **Community summary**
* **Representative embedding**
* **Relationships to member entities**

### Why communities matter?

They help in:

* Fast retrieval
* Higher-level reasoning
* Structured summarization
* Topic-based memory queries (e.g., "What does the user prefer in laptops?")

---

# ğŸ¯ Putting It All Together (Fully Explained)

### When user messages come in, Zep does:

---

### **Step 1: Store raw message â†’ Episode node**

Good for:

* Auditing
* Reference
* Re-extracting later

---

### **Step 2: Extract entities & facts â†’ Entities Subgraph**

Good for:

* Reasoning
* Retrieval
* State tracking

---

### **Step 3: Group related entities â†’ Communities**

Good for:

* Topic-level memory
* Fast clustering
* Organized context retrieval

---

# ğŸš€ A Super Simple Mini Example

Letâ€™s take just one message:

> "My sister Riya moved to Pune last month."

### Episode added:

```
E1: â€œMy sister Riya moved to Pune last month.â€
```

### Entities extracted:

* User
* Riya
* Pune
* Move Event

### Facts extracted:

```
(Riya) --is_sister_of--> (User)
(Riya) --moved_to--> (Pune) [valid: last month â†’ e.g., 2024-12-01]
```

### Community detection:

Entities cluster under:

```
â€œFamily & Residence Communityâ€
```

With relationships:

* Riya â†’ User
* Riya â†’ Pune
* Move Date

Now the agent can answer:

* â€œWhere does Riya live now?â€
* â€œWhen did she move?â€
* â€œWho in the userâ€™s family recently changed residence?â€

All because of the layered memory graph.